{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyOFiHYBUckbJ1B6lnCtaoPW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danisoaresl/Data-Analytics/blob/main/regressao_logistica_Dani.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelos de Classificação e Regressão\n",
        "\n",
        "Logística\n",
        "\n",
        "Desafio Final\n",
        "\n",
        "1. Utilizando o data set iris (iris.csv em anexo ou usandoo sklearn):\n",
        "\n",
        "Exemplo de como fazer a importação do dataset usando o sklearn\n",
        "\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "Responda:"
      ],
      "metadata": {
        "id": "AdLq-_351lZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Faça uma análise inicial sobre esse dataset"
      ],
      "metadata": {
        "id": "Fd2FRyky1oqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importação de bibliotecas\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "6mpVAKIw9vKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#dados Iris do CSV\n",
        "df_iris = pd.read_csv('/content/drive/MyDrive/iris.csv')\n",
        "\n",
        "print(\"Iris DataFrame:\")\n",
        "print(df_iris.head())\n"
      ],
      "metadata": {
        "id": "eFEtwQRd94-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_iris.isnull().sum())"
      ],
      "metadata": {
        "id": "80IH0RPfA5z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imprimir estatísticas descritivas para colunas numéricas\n",
        "print(df_iris.describe())"
      ],
      "metadata": {
        "id": "TSI8FK2--ubW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#contar o número de amostras em cada classe\n",
        "print(df_iris['Species'].value_counts())"
      ],
      "metadata": {
        "id": "BSzlqQJVCb6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Use o boxplot e o histograma para caracterizar as propriedades\n",
        "de cada uma das espécies existentes."
      ],
      "metadata": {
        "id": "LdVS2-Io1mQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_iris.columns)"
      ],
      "metadata": {
        "id": "eF8ZUgFOA2Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#definir as características do conjunto de dados Iris\n",
        "features = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width']\n",
        "\n",
        "#boxplots para cada característica\n",
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "for i, feature in enumerate(features, 1):\n",
        "    plt.subplot(2, 2, i)  #subplot de 2 linhas e 2 colunas\n",
        "    sns.boxplot(x='Species', y=feature, data=df_iris)\n",
        "    plt.title(f'Boxplot de {feature} por Espécie')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZozgDuPh0_8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#histogramas para características específicas\n",
        "df_iris[['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width']].hist(bins=20, figsize=(10, 8))\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cRTtI-7mDeyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pairplot\n",
        "sns.pairplot(df_iris, hue='Species')\n",
        "plt.suptitle(\"Pairplot do Dataset Iris\", y=1.02)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aO1bhQG4Dwwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calcular a matriz de correlação apenas com colunas numéricas\n",
        "correlation_matrix = df_iris.drop(columns='Species').corr()\n",
        "\n",
        "#plotar a matriz de correlação\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title(\"Matriz de Correlação\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sJY3Cj70EPAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Somente olhando esses gráficos, é possível afirmar que uma ou mais\n",
        "propriedades (Sepal_Length, Sepal_Width, Petal_Length, Petal_Width)\n",
        "são suficientes para distinguir as espécies?\n",
        "\n",
        "\n",
        "É possível concluir que características como petal length e petal width são as mais distintivas para separar as espécies no dataset Iris.\n"
      ],
      "metadata": {
        "id": "HdMGad4m1nj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_iris.describe()"
      ],
      "metadata": {
        "id": "hRbVel3tDezo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#boxplot para Sepal Length\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Species', y='Sepal_Length', data=df_iris)\n",
        "plt.title('Boxplot de Sepal Length por Espécie')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9AJWHu9jFUjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#histograma para Sepal Length\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=df_iris, x='Sepal_Length', hue='Species', multiple='stack', bins=15)\n",
        "plt.title('Histograma de Sepal Length por Espécie')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BkFUD0d7Fbs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#boxplot para Sepal Width\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Species', y='Sepal_Width', data=df_iris)\n",
        "plt.title('Boxplot de Sepal Width por Espécie')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wkzHlWLTF2X1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#histograma para Sepal Width\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=df_iris, x='Sepal_Width', hue='Species', multiple='stack', bins=15)\n",
        "plt.title('Histograma de Sepal Width por Espécie')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-FGbqZWPGDc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#boxplot para Petal Length\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Species', y='Petal_Length', data=df_iris)\n",
        "plt.title('Boxplot de Petal Length por Espécie')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SCBycdUbGZlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#histograma para Petal Length\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=df_iris, x='Petal_Length', hue='Species', multiple='stack', bins=15)\n",
        "plt.title('Histograma de Petal Length por Espécie')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nGvaBId2GZ2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#boxplot para Petal Width\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Species', y='Petal_Width', data=df_iris)\n",
        "plt.title('Boxplot de Petal Width por Espécie')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7_MbWfkXGaSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#histograma para Petal Width\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=df_iris, x='Petal_Width', hue='Species', multiple='stack', bins=15)\n",
        "plt.title('Histograma de Petal Width por Espécie')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aNHz_aHXGagF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verificar se há valores ausentes\n",
        "print(df_iris['Sepal_Length'].isnull().sum())"
      ],
      "metadata": {
        "id": "bjkma58AVkp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0"
      ],
      "metadata": {
        "id": "WuY6U6VP4RVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#elementos por grupo (espécie)\n",
        "print(df_iris['Species'].value_counts())"
      ],
      "metadata": {
        "id": "640PewP8VsAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Species\n",
        "\n",
        "setosa        50\n",
        "\n",
        "versicolor    50\n",
        "\n",
        "virginica     50\n",
        "\n"
      ],
      "metadata": {
        "id": "xdtM-AaFYy5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#variabilidade (desvio padrão) de 'sepal length (cm)' para cada espécie\n",
        "print(df_iris.groupby('Species')['Sepal_Length'].std())"
      ],
      "metadata": {
        "id": "jgtlbcRTWWX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Species\n",
        "\n",
        "setosa        0.352490\n",
        "\n",
        "versicolor    0.516171\n",
        "\n",
        "virginica     0.635880"
      ],
      "metadata": {
        "id": "-VvRLf6AY77p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribuições de sepal length por espécie\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Species', y='Sepal_Length', data=df_iris)\n",
        "plt.title('Distribuição de Sepal Length por Espécie')\n",
        "plt.show()\n",
        "\n",
        "#histogramas para sepal length por espécie\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=df_iris, x='Sepal_Length', hue='Species', multiple='stack', bins=15)\n",
        "plt.title('Histograma de Sepal Length por Espécie')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GFcUNaW8W5Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verificar os valores únicos em 'Species'\n",
        "print(df_iris['Species'].unique())"
      ],
      "metadata": {
        "id": "gElWlsx-5pBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separar os dados por espécie\n",
        "setosa_data = df_iris[df_iris['Species'] == 'setosa']['Sepal_Length']\n",
        "versicolor_data = df_iris[df_iris['Species'] == 'versicolor']['Sepal_Length']\n",
        "virginica_data = df_iris[df_iris['Species'] == 'virginica']['Sepal_Length']\n",
        "\n",
        "#verificar se há dados em cada grupo\n",
        "print(f\"Setosa data count: {setosa_data.count()}\")\n",
        "print(f\"Versicolor data count: {versicolor_data.count()}\")\n",
        "print(f\"Virginica data count: {virginica_data.count()}\")"
      ],
      "metadata": {
        "id": "3szTcXAd575K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "#se todos os grupos contiverem dados, realizar o teste ANOVA\n",
        "if setosa_data.count() > 0 and versicolor_data.count() > 0 and virginica_data.count() > 0:\n",
        "    f_statistic, p_value = stats.f_oneway(setosa_data, versicolor_data, virginica_data)\n",
        "\n",
        "    #resultados\n",
        "    print(\"\\nANOVA for Sepal_Length:\")\n",
        "    print(f\"F-statistic: {f_statistic}\")\n",
        "    print(f\"p-value: {p_value}\")\n",
        "\n",
        "    #verificar a significância\n",
        "    if p_value < 0.05:\n",
        "        print(\"A diferença nas médias de sepal length entre as espécies é significativa.\")\n",
        "    else:\n",
        "        print(\"A diferença nas médias de sepal length entre as espécies não é significativa.\")\n",
        "else:\n",
        "    print(\"Um ou mais grupos de dados estão vazios, o que pode estar causando o erro.\")"
      ],
      "metadata": {
        "id": "LOmgHa92XIPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "ANOVA for Sepal_Length:\n",
        "\n",
        "F-statistic: 119.26450218450468\n",
        "\n",
        "p-value: 1.6696691907693826e-31\n",
        "\n",
        "A diferença nas médias de sepal length entre as espécies é significativa."
      ],
      "metadata": {
        "id": "ovqpbmlKXXV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import shapiro\n",
        "\n",
        "#realizar o teste de normalidade de Shapiro-Wilk para cada grupo\n",
        "stat_setosa, p_setosa = shapiro(setosa_data)\n",
        "stat_versicolor, p_versicolor = shapiro(versicolor_data)\n",
        "stat_virginica, p_virginica = shapiro(virginica_data)\n",
        "\n",
        "#exibir os resultados\n",
        "print(f\"Setosa p-value: {p_setosa}\\n\")\n",
        "print(f\"Versicolor p-value: {p_versicolor}\\n\")\n",
        "print(f\"Virginica p-value: {p_virginica}\\n\")\n",
        "\n",
        "#determinar se a distribuição é normal\n",
        "if p_setosa < 0.05:\n",
        "    print(\"Setosa não segue uma distribuição normal.\\n\")\n",
        "else:\n",
        "    print(\"Setosa segue uma distribuição normal.\\n\")\n",
        "\n",
        "if p_versicolor < 0.05:\n",
        "    print(\"Versicolor não segue uma distribuição normal.\\n\")\n",
        "else:\n",
        "    print(\"Versicolor segue uma distribuição normal.\\n\")\n",
        "\n",
        "if p_virginica < 0.05:\n",
        "    print(\"Virginica não segue uma distribuição normal.\\n\")\n",
        "else:\n",
        "    print(\"Virginica segue uma distribuição normal.\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jPf3Yuq5XiYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setosa p-value: 0.4595131499174534\n",
        "\n",
        "Versicolor p-value: 0.4647370359250263\n",
        "\n",
        "Virginica p-value: 0.25831474614079086\n",
        "\n",
        "Setosa segue uma distribuição normal.\n",
        "\n",
        "Versicolor segue uma distribuição normal.\n",
        "\n",
        "Virginica segue uma distribuição normal."
      ],
      "metadata": {
        "id": "J2BaTcMOXwVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os resultados da ANOVA indicam que não há diferenças estatisticamente significativas no comprimento da sépala entre as espécies Setosa, Versicolor e Virginica. Embora existam diferenças nas médias observadas, elas não são suficientemente grandes para serem consideradas estatisticamente significativas, considerando a variabilidade dos dados."
      ],
      "metadata": {
        "id": "JtsVikZcZSKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import levene\n",
        "\n",
        "#homogeneidade de variâncias\n",
        "stat, p = levene(setosa_data, versicolor_data, virginica_data)\n",
        "print(f\"Levene's test p-value: {p}\")\n",
        "\n",
        "if p < 0.05:\n",
        "    print(\"As variâncias não são homogêneas entre as espécies.\")\n",
        "else:\n",
        "    print(\"As variâncias são homogêneas entre as espécies.\")\n"
      ],
      "metadata": {
        "id": "JSMF1hCrXupr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Levene's test p-value: 0.0022585277836218586\n",
        "\n",
        "As variâncias não são homogêneas entre as espécies."
      ],
      "metadata": {
        "id": "ZcZEXg9nYGQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O teste de Levene para homogeneidade de variâncias resultou em um p-valor de 0.0023, indicando que as variâncias entre as espécies não são homogêneas. Isso sugere que há uma diferença significativa na variabilidade do comprimento da sépala entre as espécies Setosa, Versicolor e Virginica. Esse resultado pode afetar a validade de testes de comparação de médias, como a ANOVA tradicional, que assume variâncias homogêneas entre os grupos.\n",
        "\n"
      ],
      "metadata": {
        "id": "PMKWe1HkZhCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pingouin"
      ],
      "metadata": {
        "id": "qlw5fpg3YLNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Setosa data count: {len(setosa_data)}\")\n",
        "print(f\"Versicolor data count: {len(versicolor_data)}\")\n",
        "print(f\"Virginica data count: {len(virginica_data)}\")"
      ],
      "metadata": {
        "id": "Qx4TUsto9Kja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_iris.columns)"
      ],
      "metadata": {
        "id": "hln4v3AC9dD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verificar o tamanho dos grupos\n",
        "print(f\"Setosa data count: {len(setosa_data)}\")\n",
        "print(f\"Versicolor data count: {len(versicolor_data)}\")\n",
        "print(f\"Virginica data count: {len(virginica_data)}\")"
      ],
      "metadata": {
        "id": "KWImKtM29z9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_iris['Species'].unique())"
      ],
      "metadata": {
        "id": "xyK_MgpO96lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filtrar os dados para cada espécie com base na coluna 'Species' com strings\n",
        "setosa_data = df_iris[df_iris['Species'] == 'setosa']['Sepal_Length']\n",
        "versicolor_data = df_iris[df_iris['Species'] == 'versicolor']['Sepal_Length']\n",
        "virginica_data = df_iris[df_iris['Species'] == 'virginica']['Sepal_Length']"
      ],
      "metadata": {
        "id": "xQEy2UMN-Df0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verificar o número de elementos em cada grupo\n",
        "print(f\"Setosa data count: {len(setosa_data)}\")\n",
        "print(f\"Versicolor data count: {len(versicolor_data)}\")\n",
        "print(f\"Virginica data count: {len(virginica_data)}\")"
      ],
      "metadata": {
        "id": "dVuQu4Hw-G1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "\n",
        "#preparar dados\n",
        "setosa_data = df_iris[df_iris['Species'] == 'setosa']['Sepal_Length']\n",
        "versicolor_data = df_iris[df_iris['Species'] == 'versicolor']['Sepal_Length']\n",
        "virginica_data = df_iris[df_iris['Species'] == 'virginica']['Sepal_Length']\n",
        "\n",
        "# ANOVA de Welch (usando scipy.stats.f_oneway para ANOVA padrão)\n",
        "f_statistic, p_value = stats.f_oneway(setosa_data, versicolor_data, virginica_data)\n",
        "\n",
        "#estatísticas para a ANOVA\n",
        "print(f\"ANOVA F-statistic: {f_statistic}\")\n",
        "print(f\"p-value: {p_value}\")\n",
        "\n",
        "#exibir o resultado detalhado da ANOVA usando OLS (modelo de regressão linear)\n",
        "#usando o modelo OLS do statsmodels\n",
        "model = ols('Sepal_Length ~ C(Species)', data=df_iris).fit()\n",
        "anova_table = anova_lm(model, typ=2)\n",
        "print(\"\\nTabela ANOVA (modelo OLS):\")\n",
        "print(anova_table)\n"
      ],
      "metadata": {
        "id": "6gn6L8FN86LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os resultados da ANOVA indicam uma diferença altamente significativa entre as médias de comprimento das sépalas das espécies Setosa, Versicolor e Virginica, com um p-valor extremamente pequeno (1.67e-31). Além disso, a ANOVA explicou aproximadamente 61.87% da variabilidade no comprimento das sépalas, sugerindo que a espécie tem um impacto substancial sobre essa característica. A estatística F muito alta (119.26) reforça a ideia de que as diferenças entre as espécies são grandes e estatisticamente significativas."
      ],
      "metadata": {
        "id": "ezfPJAugarZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Aplique a regressão logística para avaliar o modelo de\n",
        "classificação."
      ],
      "metadata": {
        "id": "4NO0jDhurgVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "WezCx9EHGADP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separar recursos (X) e variável de destino (y)\n",
        "X = df_iris.drop(['Species'], axis=1)  # Remova apenas a coluna 'Species'\n",
        "y = df_iris['Species']\n",
        "\n",
        "#escalonar os dados\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "#dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "jPTmqzMoGmUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#criar e treinar um modelo de regressão logística\n",
        "model = LogisticRegression(max_iter=200)  # Aumentando o número máximo de iterações\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#fazer previsões no conjunto de testes\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "2SNcpoqnK5q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#avaliar o desempenho do modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#realizar validação cruzada para uma avaliação mais robusta\n",
        "cross_val_accuracy = cross_val_score(model, X_scaled, y, cv=5).mean()  #acurácia média com validação cruzada\n",
        "cross_val_std = cross_val_score(model, X_scaled, y, cv=5).std()  #desvio padrão com validação cruzada\n",
        "\n",
        "#imprimir os resultados\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Acurácia média (validação cruzada):\", cross_val_accuracy)\n",
        "print(\"Desvio padrão (validação cruzada):\", cross_val_std)"
      ],
      "metadata": {
        "id": "NKn5qt0bGmhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix:\n",
        "\n",
        " [[10  0  0]\n",
        "\n",
        " [ 0  9  0]\n",
        "\n",
        " [ 0  0 11]]\n",
        "\n",
        "Acurácia média (validação cruzada): 0.9600000000000002\n",
        "\n",
        "Desvio padrão (validação cruzada): 0.038873012632301994"
      ],
      "metadata": {
        "id": "PLmSgTP0E-Yv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regressão Logística apresentou uma acurácia perfeita de 1.0 no conjunto de teste, com todas as amostras classificadas corretamente, como mostra a matriz de confusão sem erros entre as classes. Na validação cruzada, obteve uma acurácia média de 96% com baixo desvio padrão (0.0389), indicando desempenho consistente e alta capacidade de generalização. Isso sugere que o modelo é robusto e adequado para classificar as espécies no conjunto de dados iris."
      ],
      "metadata": {
        "id": "vLkQlsFzE4EU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. Calcule a acurácia, precisão e recall."
      ],
      "metadata": {
        "id": "VgjXYvIu3Xw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "#cálculo de métricas\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')  # 'weighted' leva em conta a proporção de cada classe\n",
        "recall = recall_score(y_test, y_pred, average='weighted')        # 'weighted' leva em conta a proporção de cada classe\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')                # F1 Score, que é a média harmônica da precisão e do recall\n",
        "\n",
        "#imprimir resultados\n",
        "print(\"Acurácia:\", accuracy)\n",
        "print(\"Precisão:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "id": "azdYrHteQRyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "acurácia: 1.0\n",
        "\n",
        "Precisão: 1.0\n",
        "\n",
        "Recall: 1.0\n",
        "\n",
        "F1 Score: 1.0"
      ],
      "metadata": {
        "id": "uJ1cceZiFYpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acurácia: 1.0 — o modelo classificou corretamente todas as amostras do conjunto de teste, sem erros;\n",
        "\n",
        "Precisão: 1.0 — para cada classe, todas as previsões positivas feitas pelo modelo estavam corretas;\n",
        "\n",
        "Recall: 1.0 — o modelo identificou corretamente todas as instâncias reais de cada classe, sem deixar de classificar nenhuma;\n",
        "\n",
        "F1 Score: 1.0 — a média harmônica entre precisão e recall é também perfeita, indicando um excelente equilíbrio entre as duas métricas."
      ],
      "metadata": {
        "id": "m23RI57OGgOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Codificar os rótulos das espécies\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# Dividir os dados\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Treinar o modelo\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "3Y3cGqj-LS9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = y_test  # substitua y_test pelos valores reais de teste\n",
        "y_pred = model.predict(X_test)  # substitua model pelo seu modelo e X_test pelos dados de teste\n",
        "\n",
        "report = classification_report(y_true, y_pred)\n",
        "print(\"Relatório de Classificação:\\n\", report)"
      ],
      "metadata": {
        "id": "VjQy4eCeG92j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "y_true (valores reais de teste)\n",
        "\n",
        "y_pred (valores previstos pelo modelo)"
      ],
      "metadata": {
        "id": "hAFsaEN7IIdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "f. Plote a matriz de confusão com matplotlib ou seaborn."
      ],
      "metadata": {
        "id": "uXGHqGiQrkQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#matriz de confusão\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "#plotando a matriz de confusão como gráfico de calor\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.xlabel(\"Previsão\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.show()\n",
        "\n",
        "#resultados\n",
        "print(\"Acurácia:\", accuracy)\n",
        "print(\"Relatório de Classificação:\\n\", report)\n",
        "print(\"Precisão média ponderada:\", precision)\n",
        "print(\"Recall médio ponderado:\", recall)"
      ],
      "metadata": {
        "id": "3qJGony7rkYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acurácia: 1.0\n",
        "\n",
        "Precisão média ponderada: 1.0\n",
        "\n",
        "Recall médio ponderado: 1.0"
      ],
      "metadata": {
        "id": "DizdBikCclEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Utilizando o dataset load_digits. Exemplo de como fazer a\n",
        "importação do dataset usando o sklearn:\n",
        "\n",
        "from sklearn.datasets import\n",
        "\n",
        "load_digits digits = load_digits()\n",
        "\n",
        "Responda:\n",
        "\n",
        "a. Faça uma análise inicial sobre esse\n",
        "dataset\n",
        "\n",
        "i. Quantos dados possui?\n",
        "\n",
        "O dataset possui 1.797 amostras e 64 características (pixels) por amostra."
      ],
      "metadata": {
        "id": "Mrp-SxNHPLaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#carregar o dataset\n",
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "\n",
        "print(digits.keys())"
      ],
      "metadata": {
        "id": "JiEdHdUBP0R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data: As intensidades dos pixels em um formato bidimensional.\n",
        "\n",
        "target: A classe do dígito (0 a 9).\n",
        "\n",
        "images: As imagens originais em formato 8x8.\n",
        "\n",
        "DESCR: Descrição completa do dataset."
      ],
      "metadata": {
        "id": "QD6w824FdQRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importar bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits"
      ],
      "metadata": {
        "id": "JOfvvPZyM0ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataFrame para facilitar a análise\n",
        "df_digits = pd.DataFrame(digits.data, columns=range(64))\n",
        "df_digits['target'] = digits.target"
      ],
      "metadata": {
        "id": "Jx2Mh952M5k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#estatísticas descritivas\n",
        "print(df_digits.describe())"
      ],
      "metadata": {
        "id": "RI1Scnx6M7r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#contagem de exemplos por classe\n",
        "print(df_digits['target'].value_counts())"
      ],
      "metadata": {
        "id": "rLQ6IRyMM9s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#contagem de exemplos por classe como uma lista em linha\n",
        "counts = df_digits['target'].value_counts().sort_index()\n",
        "print(\"Contagem de exemplos por classe (0-9):\", list(counts))\n",
        "\n",
        "#alternativamente, exibir contagem organizada por dígito\n",
        "for digit, count in counts.items():\n",
        "    print(f\"Dígito {digit}: {count} exemplos\")\n"
      ],
      "metadata": {
        "id": "g27Y2ndMd-EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#distribuição de pixels\n",
        "plt.hist(df_digits.iloc[:, 0], bins=30)\n",
        "plt.xlabel('Intensidade do pixel')\n",
        "plt.ylabel('Frequência')\n",
        "plt.title('Distribuição da intensidade do primeiro pixel')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dEiAS2EUS-5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#amostra do dígito \"1\" e exibi-la\n",
        "index_of_one = np.where(digits.target == 1)[0][0]  # Primeira ocorrência do dígito \"1\"\n",
        "image_of_one = digits.images[index_of_one]\n",
        "\n",
        "#dígito \"1\" em escala de cinza\n",
        "plt.imshow(image_of_one, cmap='gray')\n",
        "plt.title('Dígito 1 em Preto e Branco')\n",
        "plt.axis('off')  # Ocultar os eixos para uma melhor visualização\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V4Mds1ayeesv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#primeiras 5 linhas do DataFrame\n",
        "print(df_digits.head())\n"
      ],
      "metadata": {
        "id": "tG-bQCOcdes0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ii. Existem dados nulos? Se sim quantos?\n",
        "\n"
      ],
      "metadata": {
        "id": "X4H_IMJ-P4Si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#verificar se há valores nulos em todo o DataFrame\n",
        "print(df_digits.isnull().sum().sum())"
      ],
      "metadata": {
        "id": "F1oCoyvMP5U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado 0 indica que não há dados nulos."
      ],
      "metadata": {
        "id": "sLurd-Gmd2eQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "iii. Todos são dados numéricos ou existem colunas com dados\n",
        "categóricos?"
      ],
      "metadata": {
        "id": "Dss9uZ6tP8Yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#verificar os tipos de dados de cada coluna\n",
        "print(df_digits.dtypes)"
      ],
      "metadata": {
        "id": "okebQM0tP903"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todos os dados são numéricos, incluindo a coluna target."
      ],
      "metadata": {
        "id": "_zeUFE22UnQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Aplique a regressão logística para construir e avaliar o modelo de\n",
        "classificação."
      ],
      "metadata": {
        "id": "pp4WwgLpP_QC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importar as bibliotecas\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "RHt6u49RQCC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#carregar o dataset\n",
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()"
      ],
      "metadata": {
        "id": "HW2X0IsLVpiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dividir os dados em conjuntos de treinamento e teste:\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)\n",
        "\n",
        "#criar e treinar um modelo de regressão logística\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#fazer previsões:\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "#avaliar o modelo:\n",
        "#acurácia:\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Acurácia:\", accuracy)"
      ],
      "metadata": {
        "id": "rUvrijfYVrDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acurácia: 0.975"
      ],
      "metadata": {
        "id": "fNliwtFyex5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Calcule a acurácia, precisão e recall com base no desempenho do modelo."
      ],
      "metadata": {
        "id": "hzzCIpayQFZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importar bibliotecas\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "9nICcDV7S_GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#carregar o dataset\n",
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "\n",
        "#DataFrame a partir do conjunto de dados\n",
        "df_orig = pd.DataFrame(digits.data, columns=digits.feature_names)\n",
        "df_orig['target'] = digits.target\n",
        "df_orig['target_names'] = digits.target_names[digits.target]\n",
        "\n",
        "#cópia do DataFrame\n",
        "df_digits = df_orig.copy()"
      ],
      "metadata": {
        "id": "RDFBpYBPVRim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#recursos separados (X) e variável de destino (y)\n",
        "X = df_digits.drop(['target', 'target_names'], axis=1)\n",
        "y = df_digits['target']\n",
        "\n",
        "#divida os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#dimensione os recursos\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "33RxH7ofVZSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#criar e treinar um modelo de regressão logística\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#faça previsões no conjunto de testes\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "#avalie o desempenho do modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')"
      ],
      "metadata": {
        "id": "ehI05Qf0VhEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "id": "B_qvGbC-wuZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: 0.9722222222222222\n",
        "\n",
        "Precision: 0.9725212596953555\n",
        "\n",
        "Recall: 0.9722222222222222"
      ],
      "metadata": {
        "id": "N3ityB_Rgqtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Plote a matriz de confusão dos resultados do modelo utilizando matplotlib\n",
        "ou seaborn."
      ],
      "metadata": {
        "id": "j-9O6_HHQGqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#calcular a matriz de confusão\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#plotar a matriz de confusão usando Seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.xlabel(\"Previsto\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_FdzFwnoQJ6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#matriz de confusão usando Matplotlib\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(conf_matrix, interpolation='nearest', cmap='Blues')\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.colorbar()\n",
        "\n",
        "#números nas células\n",
        "for i in range(conf_matrix.shape[0]):  # linhas\n",
        "    for j in range(conf_matrix.shape[1]):  # colunas\n",
        "        plt.text(j, i, conf_matrix[i, j], ha='center', va='center', color='black')\n",
        "\n",
        "plt.xlabel(\"Previsto\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uNQgBxGAhA6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. Aplique a regressão logística para avaliar o modelo de classificação dos\n",
        "dígitos de 0 a 9 utilizando o conjunto de dados específico para esse problema\n",
        "(por exemplo, MNIST)."
      ],
      "metadata": {
        "id": "9AfOV-6cQNxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importar as bibliotecas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA  #PCA para redução de dimensionalidade"
      ],
      "metadata": {
        "id": "iUmplzc8V2Qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#carregar o dataset MNIST\n",
        "mnist = fetch_openml('mnist_784')\n",
        "\n",
        "#converter os dados para um formato NumPy\n",
        "X, y = mnist.data, mnist.target\n",
        "\n",
        "#converter as labels para números inteiros\n",
        "y = y.astype('int')\n",
        "\n",
        "#dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Lqvh67bPQOfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#escalonar os dados\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#reduzir a dimensionalidade dos dados usando PCA\n",
        "pca = PCA(n_components=50)  #reduzir para 50 componentes principais\n",
        "X_train_pca = pca.fit_transform(X_train)  #garantir que X_train_pca seja definido aqui\n",
        "X_test_pca = pca.transform(X_test)  # X_test_pca seja transformado com os mesmos componentes\n",
        "\n",
        "#criar o modelo de regressão logística\n",
        "model = LogisticRegression(solver='saga', max_iter=1000, random_state=42)\n",
        "\n",
        "#treinar o modelo\n",
        "model.fit(X_train_pca, y_train)\n",
        "\n",
        "#fazer previsões no conjunto de teste\n",
        "y_pred = model.predict(X_test_pca)"
      ],
      "metadata": {
        "id": "DWqIDeQqWPmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#acurácia\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Acurácia:\", accuracy)\n",
        "\n",
        "#matriz de confusão\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#plotar a matriz de confusão usando Matplotlib\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(conf_matrix, interpolation='nearest', cmap='Blues')\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.colorbar()\n",
        "\n",
        "#adicionar os números nas células\n",
        "for i in range(conf_matrix.shape[0]):  # Itera sobre as linhas\n",
        "    for j in range(conf_matrix.shape[1]):  # Itera sobre as colunas\n",
        "        plt.text(j, i, conf_matrix[i, j], ha='center', va='center', color='black')\n",
        "\n",
        "plt.xlabel(\"Previsto\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C2E60wiznj1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acurácia: 0.9048571428571428"
      ],
      "metadata": {
        "id": "eCzd-2Fspatm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acurácia de 0.9048 (aproximadamente 90.5%) que você obteve está bastante boa para o modelo de regressão logística aplicado ao conjunto de dados MNIST, especialmente considerando que a dimensionalidade dos dados foi reduzida para 50 componentes principais usando o PCA."
      ],
      "metadata": {
        "id": "QfXHlM9Lpg55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "f. Calcule a acurácia, precisão e recall com base no desempenho do modelo\n",
        "para a classificação dos dígitos de 0 a 9."
      ],
      "metadata": {
        "id": "0xPMGIoKQQke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calcular métricas\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "#imprimir os resultados\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "id": "-DsUGFzsQRQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: 0.9048571428571428\n",
        "\n",
        "Precision: 0.904397762765129\n",
        "\n",
        "Recall: 0.9048571428571428"
      ],
      "metadata": {
        "id": "OsNc3anzjFrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esses resultados sugerem que o modelo está performando muito bem, com boa capacidade de identificar tanto as instâncias positivas quanto negativas, sem um viés claro para uma das classes. A acurácia, precision e recall altas indicam que o modelo é eficaz e balanceado em suas previsões, com um bom desempenho geral. No entanto, se as classes no dataset forem desbalanceadas, é importante analisar também outras métricas, como a F1-Score, que combina precision e recall em uma única medida, oferecendo uma visão mais equilibrada da performance do modelo."
      ],
      "metadata": {
        "id": "-rPC_69NAfl6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "g. Plote a matriz de confusão dos resultados da classificação dos dígitos de 0\n",
        "a 9 utilizando matplotlib ou seaborn."
      ],
      "metadata": {
        "id": "Sf5vkeeiQUId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importar biblioteca\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "Y3Nh0S3ZWwoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calcular a matriz de confusão\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#plotar a matriz de confusão usando Seaborn\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=np.arange(10), yticklabels=np.arange(10))\n",
        "plt.xlabel(\"Previsto\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.title(\"Matriz de Confusão para Classificação dos Dígitos de 0 a 9\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "563ogKkhQU9G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}